{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ea0a54-0909-4d1c-acc5-1f9064811cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This script is used to take the normalized data available in the Human Cell Atlas, and convert this back into raw counts\n",
    "authors: Roy Oelen\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a212ea-53fa-4f99-8bd0-8580c052fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries required\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sparse\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14f653c0-2eb3-46dc-9650-c56259a7999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# locations of relevant object\n",
    "hca_loc = '/groups/umcg-franke-scrna/tmp02/external_datasets/hca/Global_lognormalised.h5ad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "923d67ec-1f9c-4aad-84c8-9b224b86867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read object\n",
    "hca = sc.read_h5ad(hca_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2b62ce2-5b1b-4301-a2c9-09a92df5b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how may cells we have\n",
    "ncells = hca.obs.shape[0]\n",
    "# set the slice size, how many cells will we read and write at a time\n",
    "slice_size = 10000\n",
    "# set where to store the results\n",
    "slices_location = \"/groups/umcg-franke-scrna/tmp02/releases/blokland-2020/v1/epicardial_fat/ongoing/rtcd/references/hca/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f044abf-d541-4f8e-a329-d435bfab8ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing slice 1 to 10000\n",
      "doing slice 10001 to 20000\n",
      "doing slice 20001 to 30000\n",
      "doing slice 30001 to 40000\n",
      "doing slice 40001 to 50000\n",
      "doing slice 50001 to 60000\n",
      "doing slice 60001 to 70000\n",
      "doing slice 70001 to 80000\n",
      "doing slice 80001 to 90000\n",
      "doing slice 90001 to 100000\n",
      "doing slice 100001 to 110000\n",
      "doing slice 110001 to 120000\n",
      "doing slice 120001 to 130000\n",
      "doing slice 130001 to 140000\n"
     ]
    }
   ],
   "source": [
    "# loop through slices\n",
    "for i_left in range(0, ncells, slice_size):\n",
    "    # set the right side of the slice\n",
    "    i_right = i_left + slice_size\n",
    "    # unless of course we are at the last slice, which is a bit smaller (remember 0-based indexing and the right bound being exclusive)\n",
    "    if ncells < i_right:\n",
    "        i_right = ncells\n",
    "    # message which slice we are doing\n",
    "    print(' '.join(['doing slice', str(i_left + 1), 'to', str(i_right)]))\n",
    "\n",
    "    # take a small slice\n",
    "    hca_count_slice = hca.X.tocsr()[np.arange(i_left, (i_right), 1),:]\n",
    "    # reverse natural log to the power of the number to get back to the fractions\n",
    "    hca_count_slice = hca_count_slice.expm1()\n",
    "\n",
    "    # create an np matrix from the total counts\n",
    "    total_counts = hca.obs.iloc[i_left : i_right, 15].to_numpy()\n",
    "    # multiply the fractions by the total counts\n",
    "    hca_count_slice = hca_count_slice.multiply(total_counts[:, np.newaxis])\n",
    "    # undo the scaling factor\n",
    "    hca_count_slice = hca_count_slice.multiply(1/10000)\n",
    "\n",
    "    # round to the nearest integer\n",
    "    hca_count_slice.data = np.round(hca_count_slice.data, 0)\n",
    "\n",
    "    # get the location to store the slice\n",
    "    slice_loc = ''.join([slices_location, 'expression_slice_', str(i_left), '_', str(i_right), '.mtx'])\n",
    "    # save the result\n",
    "    sio.mmwrite(slice_loc, hca_count_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "89e63767-59e2-4a8f-9b90-f928bf8d1c98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6094., 6254., 5864., 4922., 4713.], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the total counts as reported in the metadata\n",
    "total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "77fbf9de-bee2-42aa-bf03-de35819e8349",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[6092.],\n",
       "        [6250.],\n",
       "        [5863.],\n",
       "        [4920.],\n",
       "        [4712.]], dtype=float32)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and see that these are the same as the sums of each cell\n",
    "hca_count_slice.sum(axis = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
