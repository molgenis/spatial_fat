{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fb0c745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis script is used to perform deconvolution with tangram\\n\\nauthors: Roy Oelen\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script is used to perform deconvolution with tangram\n",
    "\n",
    "authors: Roy Oelen\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fb20317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the libraries\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "import scipy\n",
    "import torch\n",
    "import tangram as tg\n",
    "import pickle\n",
    "import scipy.sparse as sparse\n",
    "\n",
    "tg.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1360418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objects\n",
    "class MappingResult:\n",
    "    \"\"\"\n",
    "    Object to the results of Tangram mapping\n",
    "    \"\"\"\n",
    "    def __init__(self, spatial_object, single_cell_object, mapping):\n",
    "        \"\"\"constructor\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        spatial_object : AnnData\n",
    "            AnnData scanpy object of ST\n",
    "        single_cell_object : AnnData\n",
    "            AnnData scanpy object of SC\n",
    "        mapping : AnnData\n",
    "            AnnData resulting file\n",
    "        \n",
    "        \"\"\"\n",
    "        self.__spatial_object = spatial_object\n",
    "        self.__single_cell_object = single_cell_object\n",
    "        self.__mapping = mapping\n",
    "    \n",
    "    def get_spatial_object(self):\n",
    "        \"\"\"get ST object used for the mapping\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        result\n",
    "           The spatial object used for the mapping \n",
    "        \"\"\"\n",
    "        return self.__spatial_object\n",
    "    \n",
    "    def get_single_cell_object(self):\n",
    "        \"\"\"get SC object used for the mapping\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        result\n",
    "           The single cell object used for the mapping \n",
    "        \"\"\"\n",
    "        return self.__single_cell_object\n",
    "    \n",
    "    def get_mapping(self):\n",
    "        \"\"\"get the mapping result object\n",
    "        \n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        result\n",
    "          The object created from doing the Tangram mapping\n",
    "        \"\"\"\n",
    "        return self.__mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3baa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_tangram_mapping(slices_dict, reference, n_genes=500, mode='cells'):\n",
    "    \"\"\"perform tangram mapping on a dictionary\n",
    "        \n",
    "    Parameters\n",
    "    ----------\n",
    "    slices_dict : dict\n",
    "        the dictionary of ST objects to do the mapping for\n",
    "    reference : AnnData\n",
    "        the reference AnnData SC object to use for mapping\n",
    "    n_genes : int\n",
    "        the top number of most variable genes to use for the mapping\n",
    "    mode : str\n",
    "        the mode to use\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    result\n",
    "       a pandas dataframe instance of the expression data for the given cell type, or None if the cell type supplied doesn't exist\n",
    "    \"\"\"\n",
    "    # we will store the results in a dictionary\n",
    "    mapped_slices = {}\n",
    "    # check each slice\n",
    "    for slice_name,slice_object in slices_dict.items():\n",
    "        # calculate variable genes\n",
    "        variable_table = sc.pp.highly_variable_genes(slice_object, inplace = False, flavor='seurat_v3', n_top_genes=n_genes)\n",
    "        # select the markers\n",
    "        markers = list(variable_table[(variable_table[\"highly_variable\"] == True) & (variable_table[\"highly_variable_rank\"] <= n_genes)].index)\n",
    "        # get overlapping markers\n",
    "        tg.pp_adatas(reference, slice_object, genes=markers)\n",
    "        # do mapping\n",
    "        ad_map = tg.map_cells_to_space(\n",
    "            adata_sc=reference,\n",
    "            adata_sp=slice_objects_reloaded['V10A20-016_D1'],\n",
    "#             device='cpu',\n",
    "            device='cuda:0',\n",
    "            mode=mode\n",
    "        )\n",
    "        tg.project_cell_annotations(ad_map, ad_sp, annotation='cell_type')\n",
    "        # create an object to store the result\n",
    "        mapping_result = MappingResult(slice_object, reference, ad_map)\n",
    "        # put in a dictionary\n",
    "        mapped_slices[slice_name] = mapping_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b36e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ST data\n",
    "slice_objects_reloaded = None\n",
    "with open(''.join(['/groups/umcg-franke-scrna/tmp02/projects/epifat/ongoing/seurat_preprocess_samples/objects/', 'spaceranger.20230823.pickle']), 'rb') as f:\n",
    "    slice_objects_reloaded = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5cd65bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the reference\n",
    "reference  = sc.read_h5ad('/groups/umcg-franke-scrna/tmp02/external_datasets/hca/Global_lognormalised.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6dd544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_table = sc.pp.highly_variable_genes(slice_objects_reloaded['V10A20-016_D1'], inplace = False, flavor='seurat_v3', n_top_genes=500)\n",
    "markers = list(variable_table[(variable_table[\"highly_variable\"] == True) & (variable_table[\"highly_variable_rank\"] <= 100)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "935670fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:101 training genes are saved in `uns``training_genes` of both single cell and spatial Anndatas.\n",
      "INFO:root:12743 overlapped genes are saved in `uns``overlap_genes` of both single cell and spatial Anndatas.\n",
      "INFO:root:uniform based density prior is calculated and saved in `obs``uniform_density` of the spatial Anndata.\n",
      "INFO:root:rna count based density prior is calculated and saved in `obs``rna_count_based_density` of the spatial Anndata.\n"
     ]
    }
   ],
   "source": [
    "tg.pp_adatas(reference, slice_objects_reloaded['V10A20-016_D1'], genes=markers)\n",
    "# tg.pp_adatas(reference, slice_objects_reloaded['V10A20-016_D1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33ebe231",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Allocate tensors for mapping.\n",
      "INFO:root:Begin training with 101 genes and rna_count_based density_prior in cells mode...\n",
      "INFO:root:Printing scores every 100 epochs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.088, KL reg: 0.013\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 5.67 GiB (GPU 0; 44.35 GiB total capacity; 39.92 GiB already allocated; 3.80 GiB free; 39.93 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ad_map \u001b[38;5;241m=\u001b[39m \u001b[43mtg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_cells_to_space\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43madata_sc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43madata_sp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mslice_objects_reloaded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mV10A20-016_D1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;43;03m#     device='cpu',\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcells\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tangram-env/lib/python3.8/site-packages/tangram/mapping_utils.py:316\u001b[0m, in \u001b[0;36mmap_cells_to_space\u001b[0;34m(adata_sc, adata_sp, cv_train_genes, cluster_label, mode, device, learning_rate, num_epochs, scale, lambda_d, lambda_g1, lambda_g2, lambda_r, lambda_count, lambda_f_reg, target_count, random_state, verbose, density_prior)\u001b[0m\n\u001b[1;32m    310\u001b[0m     mapper \u001b[38;5;241m=\u001b[39m mo\u001b[38;5;241m.\u001b[39mMapper(\n\u001b[1;32m    311\u001b[0m         S\u001b[38;5;241m=\u001b[39mS, G\u001b[38;5;241m=\u001b[39mG, d\u001b[38;5;241m=\u001b[39md, device\u001b[38;5;241m=\u001b[39mdevice, random_state\u001b[38;5;241m=\u001b[39mrandom_state, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhyperparameters,\n\u001b[1;32m    312\u001b[0m     )\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;66;03m# TODO `train` should return the loss function\u001b[39;00m\n\u001b[0;32m--> 316\u001b[0m     mapping_matrix, training_history \u001b[38;5;241m=\u001b[39m \u001b[43mmapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_each\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_each\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;66;03m# constrained mode\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstrained\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/tangram-env/lib/python3.8/site-packages/tangram/mapping_optimizer.py:187\u001b[0m, in \u001b[0;36mMapper.train\u001b[0;34m(self, num_epochs, learning_rate, print_each)\u001b[0m\n\u001b[1;32m    184\u001b[0m         training_history[keys[i]]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(run_loss[i]))\n\u001b[1;32m    186\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 187\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# take final softmax w/o computing gradients\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tangram-env/lib/python3.8/site-packages/torch/tensor.py:195\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, gradient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, retain_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, create_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    168\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Computes the gradient of current tensor w.r.t. graph leaves.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m    The graph is differentiated using the chain rule. If the tensor is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m            products. Defaults to ``False``.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 195\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tangram-env/lib/python3.8/site-packages/torch/autograd/__init__.py:97\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m---> 97\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 5.67 GiB (GPU 0; 44.35 GiB total capacity; 39.92 GiB already allocated; 3.80 GiB free; 39.93 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "ad_map = tg.map_cells_to_space(\n",
    "    adata_sc=reference,\n",
    "    adata_sp=slice_objects_reloaded['V10A20-016_D1'],\n",
    "#     device='cpu',\n",
    "    device='cuda:0',\n",
    "    mode='cells'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffae8e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try with all of them\n",
    "mapping_all = perform_tangram_mapping(slice_objects_reloaded, reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eab01776",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy.sparse._csr'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m slice_objects_raw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/groups/umcg-franke-scrna/tmp02/projects/epifat/ongoing/seurat_preprocess_samples/objects/\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspaceranger.20230823.raw.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m]), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m----> 4\u001b[0m     slice_objects_raw \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scipy.sparse._csr'"
     ]
    }
   ],
   "source": [
    "# now try with the raw data instead\n",
    "slice_objects_raw = None\n",
    "with open(''.join(['/groups/umcg-franke-scrna/tmp02/projects/epifat/ongoing/seurat_preprocess_samples/objects/', 'spaceranger.20230823.raw.pickle']), 'rb') as f:\n",
    "    slice_objects_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfc127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# as well as the raw reference\n",
    "reference_raw = None\n",
    "with open('/groups/umcg-franke-scrna/tmp02/releases/blokland-2020/v1/epicardial_fat/ongoing/rtcd/references/hca/raw_expression.pickle', 'rb') as f:\n",
    "    reference_raw = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
